#!/usr/bin/env python3

import os
import sys
import pprint

from minimizer.grid import environments
from minimizer import tools
from minimizer.planning import auxiliary
from minimizer.parser import Parser
from minimizer.evaluator import Evaluator
from minimizer.planning.generators import RemoveObjects, ReplaceLiteralsWithTruth
from minimizer.planning.pddl_writer import write_PDDL
from minimizer.run import Run, run_and_parse_all
from minimizer.main import main

script_path = tools.get_script_path()
script_dir = os.path.dirname(script_path)

domain_filename = os.path.join(script_dir, "cntr-domain.pddl")
problem_filename = os.path.join(script_dir, "cntr-problem.pddl")

# The Fast Downward issue we use for this example is from 2014. The code of the
# planner from that time is only compatible with Python versions < 3.8.
try:
    interpreter = os.environ["PYTHON_3_7"]
    planner = os.environ["DOWNWARD_REPO"]
except KeyError:
    msg = """
Make sure to set the environment variables PYTHON_3_7 and DOWNWARD_REPO.
PYTHON_3_7:     Path to Python 3.7 executable (due to older Fast Downward version).
DOWNWARD_REPO:  Path to Fast Downward repository (https://github.com/aibasel/downward)
                at commit 09ccef5fd.
    """
    sys.exit(msg)

# The bug we want to isolate occurs in the translate module, so we define
# a shortcut to it.
translator = os.path.join(planner, "src/translate/translate.py")

# We want the dynamically generated PDDL file names (generated by the function
# from the auxiliary module we use further down) to be passed to the command,
# which we achieve by using the following two string placeholders in the command:
command = [
    interpreter,
    translator,
    "{generated_pddl_domain_filename}",
    "{generated_pddl_problem_filename}"]

# Here, we define the initial state the search should be started from. Generally, you can
# store anything in this dictionary that could be useful for the minimization task.
initial_state = {
    # We are  creating the entry "pddl_task" because further down we are using the
    # state_with_generated_pddl_files function from the auxiliary module and it expects
    # the PDDL task to be stored behind that keyword.
    "pddl_task": auxiliary.parse_pddl_task(domain_filename, problem_filename),
    # Similarly, we are creating the entry "runs" because we want to be able to use the
    # convenient run_and_parse_all function further down and it expects your runs to be
    # accessible through that keyword.
    "runs": {
        # The required arguments for a run object are *command* and *time_limit*, which
        # is in [s]. Additionally, here we are making use of the option of setting the
        # *memory_limit*, for the execution of *command*, which is in [MiB].
        "issue335": Run(command, time_limit=20, memory_limit=3338)
    }
}

# The parser allows us to generate properties for an executed run
# which we then can access and use for the evaluation of a state
parser = Parser()

# This function checks whether the given string is present in the
# output log *content* and adds an entry with the resulting boolean
# to the properties dictionary *props*.
def assertion_error(content, props):
    props["assertion_error"] = "AssertionError: Negated axiom impossible" in content


# Here we are telling the parser to use the function we just defined
# above. Currently, you need to specify the name of the run object
# the function should be used on, which in our case is "issue335".
parser.add_function(assertion_error, "issue335")

# The Evaluator implementation we are defining here will later be passed
# to the search function. We are required to implement the *evaluate*
# function, because it will be executed during the search every time a state
# needs to be evaluated.
class MyEvaluator(Evaluator):
    def evaluate(self, state):
        # The following context manager generates temporary PDDL files for
        # the pddl task stored in *state* so they can be used in the execution
        # of the run.
        with auxiliary.state_with_generated_pddl_files(state) as local_state:
            # run_and_parse_all is a convenient function that executes all the
            # runs we defined within the provided limit(s) and applies the above
            # defined parser to the output logs of each run. The properties dictionary
            # generated from the parsed logs is returned and stored in *results*.
            results = run_and_parse_all(local_state, parser)
        # Here we make the evaluation depend on an entry of the properties dictionary.
        return results["issue335"]["stderr"]["assertion_error"]


# The defined environment depends on where you want to execute the search:
#   - on you local machine
#   - on a Slurm computing grid
my_environment = environments.BaselSlurmEnvironment(
    export=["PATH", "PYTHON_3_7", "DOWNWARD_REPO"])

# To start the search, we need to pass the initial state, the successor
# generator(s), the evaluator class and the environment to be used to the
# main function, which will return the resulting state, once the search
# is finished.
result = main(initial_state,
              [RemoveObjects, ReplaceLiteralsWithTruth],
              MyEvaluator,
              my_environment)

# If you want the modified PDDL task to be dumped to files (which you
# probably do!), you need to explicitly to this here. Otherwise, it
# will fall prey to the garbage collector when this script ends!
write_PDDL(result["pddl_task"], "result-domain.pddl", "result-problem.pddl")

# If you are curious how you resulting state is built up, this line
# will print a structured dump of it to the command line. Of course,
# this is completely optional.
pprint.pprint(result)


# A note on successor generators:
# For this example, we chose to use two successor generators (RemoveObjects
# and ReplaceLiteralsWithTruth) that are already implemented and can be used
# to transform PDDL tasks. Implementations of the SuccesssorGenerator class
# are required to have a *get_successors(state)* function that returns a generator
# of states which are considered the successors. The way a successor generator
# is implemented determines how the state and your run(s) look(s) after the search
# is completed. Like the evaluator, successor generators may have to be
# tailored exactly to your use case.
